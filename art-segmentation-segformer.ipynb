{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8986504,"sourceType":"datasetVersion","datasetId":5167996},{"sourceId":81205,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":67484,"modelId":92561}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    break\n    if 'art-seg-ready' in dirname:\n        continue\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-24T16:26:57.391829Z","iopub.execute_input":"2024-07-24T16:26:57.392217Z","iopub.status.idle":"2024-07-24T16:26:58.421873Z","shell.execute_reply.started":"2024-07-24T16:26:57.392183Z","shell.execute_reply":"2024-07-24T16:26:58.420985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:26:58.423803Z","iopub.execute_input":"2024-07-24T16:26:58.424313Z","iopub.status.idle":"2024-07-24T16:27:12.980553Z","shell.execute_reply.started":"2024-07-24T16:26:58.424276Z","shell.execute_reply":"2024-07-24T16:27:12.979494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport glob\nimport shutil\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nimport random\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport torch\nfrom torchvision import datasets,models\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.transforms import v2\nfrom torchvision.transforms import ColorJitter\nfrom transformers import SegformerImageProcessor\nimport evaluate\nfrom torch import nn\nimport torch.nn.functional as F\nimport wandb\nimport scipy\n\n\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:27:12.981980Z","iopub.execute_input":"2024-07-24T16:27:12.982291Z","iopub.status.idle":"2024-07-24T16:27:32.396786Z","shell.execute_reply.started":"2024-07-24T16:27:12.982263Z","shell.execute_reply":"2024-07-24T16:27:32.396052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_name = 'SegFormer-full-cont-jitter'\nwandb.init(project='aimlproject', name=run_name,save_code=True, config={\n            \"epochs\": 2,\n           \"batch_size\": 32,\n              \"lr\": 5e-5,\n          \"checkpoint\": \"nvidia/segformer-b0-finetuned-ade-512-512\",\n           \"model_name\":\"SegFormer\", \"early_stopping\":False})  # mode='disabled',\nconfig = wandb.config","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:28:35.791881Z","iopub.execute_input":"2024-07-24T16:28:35.792791Z","iopub.status.idle":"2024-07-24T16:29:25.681207Z","shell.execute_reply.started":"2024-07-24T16:28:35.792756Z","shell.execute_reply":"2024-07-24T16:29:25.680155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.config\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:29:25.683458Z","iopub.execute_input":"2024-07-24T16:29:25.683749Z","iopub.status.idle":"2024-07-24T16:29:25.690186Z","shell.execute_reply.started":"2024-07-24T16:29:25.683724Z","shell.execute_reply":"2024-07-24T16:29:25.688986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2label = {\n            0: 'background',\n            1: 'bird',\n            2: 'boat',\n            3: 'bottle',\n            4: 'cat',\n            5: 'chair',\n            6: 'cow',\n            7: 'dog',\n            8: 'horse',\n            9: 'person',\n            10: 'pottedplant',\n            11: 'sheep',\n}\n\nlabel2id = {v: k for k, v in id2label.items()}\nmodel_checkpoint = config.checkpoint\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:29:25.691453Z","iopub.execute_input":"2024-07-24T16:29:25.691792Z","iopub.status.idle":"2024-07-24T16:29:25.699799Z","shell.execute_reply.started":"2024-07-24T16:29:25.691760Z","shell.execute_reply":"2024-07-24T16:29:25.698939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EXPR_PATH = '/kaggle/input/art-seg-ready/pascal_sbd_styled_expressionism2/kaggle/working/pascal_sbd_styled_expressionism'\nIMPR_PATH = '/kaggle/input/art-seg-ready/pascal_sbd_styled_impressionism2/kaggle/working/pascal_sbd_styled_impressionism'\nPIMP_PATH = '/kaggle/input/art-seg-ready/pascal_sbd_styled_post_impressionism2/kaggle/working/pascal_sbd_styled_post_impressionism'\nREAL_PATH = '/kaggle/input/art-seg-ready/pascal_sbd_styled_realism2/kaggle/working/pascal_sbd_styled_realism'\nPATHS = [ EXPR_PATH, IMPR_PATH, PIMP_PATH, REAL_PATH ]\nPATHS_IM = [ os.path.join(path, 'images') for path in PATHS ]\nPATHS_LAB = [ os.path.join(path, 'labels') for path in PATHS ]","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:29:25.700951Z","iopub.execute_input":"2024-07-24T16:29:25.701415Z","iopub.status.idle":"2024-07-24T16:29:25.710543Z","shell.execute_reply.started":"2024-07-24T16:29:25.701391Z","shell.execute_reply":"2024-07-24T16:29:25.709675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATHS","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:29:25.713324Z","iopub.execute_input":"2024-07-24T16:29:25.713645Z","iopub.status.idle":"2024-07-24T16:29:25.722363Z","shell.execute_reply.started":"2024-07-24T16:29:25.713622Z","shell.execute_reply":"2024-07-24T16:29:25.721435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(os.listdir('/kaggle/input/art-seg-ready/pascal_sbd_styled_realism1/pascal_sbd_styled_realism1/kaggle/working/pascal_sbd_styled_realism/images'))\ndef plot_random_images(allstyles=True,path=''):\n    selected_images = []\n    if allstyles:\n    #image_files = [f for f in os.listdir(basepath + '/dataset'+config.dataset+trainfolder) if f.startswith(startchar)]\n        shuffled_paths = PATHS_IM\n        random.shuffle(shuffled_paths)\n        \n        for i in range(len(PATHS)-1):\n            path = shuffled_paths[i]\n            image_files = os.listdir(path)\n            image_files = random.sample(image_files, 2) \n            image_files = [ os.path.join(path, image) for image in image_files]\n            selected_images += image_files\n            \n            \n        path = shuffled_paths[3]\n\n        image_files = os.listdir(path)\n        image_files = random.sample(image_files,3)\n        image_files = [ os.path.join(path, image) for image in image_files]\n        selected_images += image_files\n             \n    else:\n        if path == '':\n            print('empty path, useless')\n            return \n        image_files = os.listdir(path)\n        image_files = random.sample(image_files, 9)\n        image_files = [ os.path.join(path, image) for image in image_files]\n        selected_images += image_files\n\n    #selected_images = random.sample(image_files, 9)\n\n    rows = 3\n    cols = 3\n    fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n\n    # Plot each selected image\n    for i, image_name in enumerate(selected_images):\n        #img_path = os.path.join(basepath + '/dataset'+config.dataset+trainfolder, image_name)\n        img = mpimg.imread(image_name)\n        ax = axes[i // cols, i % cols]\n        ax.imshow(img)\n        ax.axis('off')\n\n    # Adjust layout\n    plt.tight_layout()\n    plt.show()\n\nplot_random_images()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:29:25.723488Z","iopub.execute_input":"2024-07-24T16:29:25.724063Z","iopub.status.idle":"2024-07-24T16:29:26.996611Z","shell.execute_reply.started":"2024-07-24T16:29:25.724038Z","shell.execute_reply":"2024-07-24T16:29:26.995599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_list = []\nfor i in range(4):\n    style_list = os.listdir(PATHS_LAB[i])\n    style_list = [ os.path.join(PATHS_LAB[i], image) for image in style_list]\n    train_list += style_list\n    \n    \n#train_list,test_list = train_test_split(train_list, test_size=0.2, random_state=0)\ntrain_list,val_list = train_test_split(train_list, test_size=0.2, random_state=0)\n\n#print(train_list[1], train_list[-1])\nexample_conv = train_list[2020]\nexample_conv = example_conv[:-4] + '.jpg'\n#example_conv = os.path.join()\nexample_conv = example_conv.replace(\"/labels/\", \"/images/\")\nprint(example_conv)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:29:26.997802Z","iopub.execute_input":"2024-07-24T16:29:26.998120Z","iopub.status.idle":"2024-07-24T16:29:32.032940Z","shell.execute_reply.started":"2024-07-24T16:29:26.998094Z","shell.execute_reply":"2024-07-24T16:29:32.031968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_list[0]\nval_list[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:29:32.034169Z","iopub.execute_input":"2024-07-24T16:29:32.034495Z","iopub.status.idle":"2024-07-24T16:29:32.040459Z","shell.execute_reply.started":"2024-07-24T16:29:32.034469Z","shell.execute_reply":"2024-07-24T16:29:32.039453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PaintingSegDataset(Dataset):\n    def __init__(self, file_list, transform=None,use_gpu=torch.cuda.is_available()): #df(1st)\n        self.file_list = file_list\n        self.transform = transform\n        self.filelength = len(file_list)\n        self.jitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1) \n        self.use_gpu = use_gpu\n        self.id_to_trainid = {\n            0: 0,\n            3: 1,\n            4: 2,\n            5: 3,\n            8: 4,\n            9: 5,\n            10: 6,\n            12: 7,\n            13: 8,\n            15: 9,\n            16: 10,\n            17: 11,\n        }\n        self.debug = True\n\n\n    def __len__(self):\n        return self.filelength\n\n    def __getitem__(self, idx):\n        label_path = self.file_list[idx]\n        \n        img_path = label_path[:-4] + '.jpg'\n        img_path = img_path.replace(\"/labels/\", \"/images/\")\n        #print(img_path)\n        img_orig = Image.open(img_path).convert('RGB')\n        \n        if label_path[-3:] == 'png':\n            label = np.array(Image.open(label_path), dtype=np.float32)\n        else:  # .mat\n            label = scipy.io.loadmat(label_path)[\"GTcls\"][0]['Segmentation'][0]\n            \n        #?name =\n        #print(label)\n        label_copy = 255 * np.ones(label.shape, dtype=np.int8)\n        for k, v in self.id_to_trainid.items():\n            label_copy[label == k] = v\n        label = Image.fromarray(label_copy)\n        #label = label.convert('L')\n        #transform = v2.Compose([v2.Resize((512,512))])\n        #img_orig = transform(img_orig)\n        #print(tensor.unique())  \n        img_jitter = self.jitter(img_orig)\n        inputs = self.transform(images=img_jitter, segmentation_maps=label, return_tensors=\"pt\", do_reduce_labels=False)\n        #print(inputs)\n        img = inputs[\"pixel_values\"].squeeze()  # Remove batch dimension\n        label = inputs[\"labels\"].squeeze()\n        #print(img.shape)\n        #print(label.shape)\n        if self.use_gpu:\n            img = img.cuda()\n            label = label.cuda()\n       \n        return img, label","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:38.781663Z","iopub.execute_input":"2024-07-24T16:30:38.782370Z","iopub.status.idle":"2024-07-24T16:30:38.796194Z","shell.execute_reply.started":"2024-07-24T16:30:38.782336Z","shell.execute_reply":"2024-07-24T16:30:38.795049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimage_processor = SegformerImageProcessor.from_pretrained(model_checkpoint)\n\n####test_dataset = PaintingSegDataset(test_list,transform=image_processor) #df\nval_dataset = PaintingSegDataset(val_list,transform=image_processor) #df\ntrain_dataset = PaintingSegDataset(train_list,transform=image_processor)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:38.798009Z","iopub.execute_input":"2024-07-24T16:30:38.798362Z","iopub.status.idle":"2024-07-24T16:30:38.898914Z","shell.execute_reply.started":"2024-07-24T16:30:38.798336Z","shell.execute_reply":"2024-07-24T16:30:38.898067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vizualize=False\n\ndef color_palette():\n    \"\"\"Color palette that maps each class to RGB values.\n    \n    This one is actually taken from ADE20k.\n    \"\"\"\n    return [[120, 120, 120], [180, 120, 120], [6, 230, 230], [80, 50, 50],\n            [4, 200, 3], [120, 120, 80], [140, 140, 140], [204, 5, 255],\n            [230, 230, 230], [4, 250, 7], [224, 5, 255], [235, 255, 7],\n            [150, 5, 61], [120, 120, 70], [8, 255, 51], [255, 6, 82],\n            [143, 255, 140], [204, 255, 4], [255, 51, 7], [204, 70, 3],\n            [0, 102, 200], [61, 230, 250], [255, 6, 51], [11, 102, 255],\n            [255, 7, 71], [255, 9, 224], [9, 7, 230], [220, 220, 220],\n            [255, 9, 92], [112, 9, 255], [8, 255, 214], [7, 255, 224],\n            [255, 184, 6], [10, 255, 71], [255, 41, 10], [7, 255, 255],\n            [224, 255, 8], [102, 8, 255], [255, 61, 6], [255, 194, 7],\n            [255, 122, 8], [0, 255, 20], [255, 8, 41], [255, 5, 153],\n            [6, 51, 255], [235, 12, 255], [160, 150, 20], [0, 163, 255],\n            [140, 140, 140], [250, 10, 15], [20, 255, 0], [31, 255, 0],\n            [255, 31, 0], [255, 224, 0], [153, 255, 0], [0, 0, 255],\n            [255, 71, 0], [0, 235, 255], [0, 173, 255], [31, 0, 255],\n            [11, 200, 200], [255, 82, 0], [0, 255, 245], [0, 61, 255],\n            [0, 255, 112], [0, 255, 133], [255, 0, 0], [255, 163, 0],\n            [255, 102, 0], [194, 255, 0], [0, 143, 255], [51, 255, 0],\n            [0, 82, 255], [0, 255, 41], [0, 255, 173], [10, 0, 255],\n            [173, 255, 0], [0, 255, 153], [255, 92, 0], [255, 0, 255],\n            [255, 0, 245], [255, 0, 102], [255, 173, 0], [255, 0, 20],\n            [255, 184, 184], [0, 31, 255], [0, 255, 61], [0, 71, 255],\n            [255, 0, 204], [0, 255, 194], [0, 255, 82], [0, 10, 255],\n            [0, 112, 255], [51, 0, 255], [0, 194, 255], [0, 122, 255],\n            [0, 255, 163], [255, 153, 0], [0, 255, 10], [255, 112, 0],\n            [143, 255, 0], [82, 0, 255], [163, 255, 0], [255, 235, 0],\n            [8, 184, 170], [133, 0, 255], [0, 255, 92], [184, 0, 255],\n            [255, 0, 31], [0, 184, 255], [0, 214, 255], [255, 0, 112],\n            [92, 255, 0], [0, 224, 255], [112, 224, 255], [70, 184, 160],\n            [163, 0, 255], [153, 0, 255], [71, 255, 0], [255, 0, 163],\n            [255, 204, 0], [255, 0, 143], [0, 255, 235], [133, 255, 0],\n            [255, 0, 235], [245, 0, 255], [255, 0, 122], [255, 245, 0],\n            [10, 190, 212], [214, 255, 0], [0, 204, 255], [20, 0, 255],\n            [255, 255, 0], [0, 153, 255], [0, 41, 255], [0, 255, 204],\n            [41, 0, 255], [41, 255, 0], [173, 0, 255], [0, 245, 255],\n            [71, 0, 255], [122, 0, 255], [0, 255, 184], [0, 92, 255],\n            [184, 255, 0], [0, 133, 255], [255, 214, 0], [25, 194, 194],\n            [102, 255, 0], [92, 0, 255]]\nif vizualize:\n    palette = color_palette()\n\n    v_index = 101\n    segmentation_map = train_dataset[v_index][1]\n    image = train_dataset[v_index][2]\n    print(segmentation_map)\n\n    color_segmentation_map = np.zeros((segmentation_map.shape[0], segmentation_map.shape[1], 3), dtype=np.uint8) # height, width, 3\n    for label, color in enumerate(palette):\n        color_segmentation_map[segmentation_map - 1 == label, :] = color\n    #print(ground_truth_color_seg.shape)\n    # Convert to BGR\n    ground_truth_color_seg = color_segmentation_map[..., ::-1]\n    img = np.array(image)\n    print(img.shape)\n    #img = np.transpose(img)\n    print(img.shape)\n    img = img * 0.5 + ground_truth_color_seg * 0.5\n    img = img.astype(np.uint8)\n\n    plt.figure(figsize=(15, 10))\n    plt.imshow(img)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:38.900028Z","iopub.execute_input":"2024-07-24T16:30:38.900324Z","iopub.status.idle":"2024-07-24T16:30:38.933036Z","shell.execute_reply.started":"2024-07-24T16:30:38.900298Z","shell.execute_reply":"2024-07-24T16:30:38.932166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = config.batch_size \ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n#test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:38.934101Z","iopub.execute_input":"2024-07-24T16:30:38.934357Z","iopub.status.idle":"2024-07-24T16:30:38.946084Z","shell.execute_reply.started":"2024-07-24T16:30:38.934334Z","shell.execute_reply":"2024-07-24T16:30:38.945117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(train_loader)\na,b = next(dataiter)\nprint(a.shape)\nprint(b.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:38.949394Z","iopub.execute_input":"2024-07-24T16:30:38.949875Z","iopub.status.idle":"2024-07-24T16:30:41.172622Z","shell.execute_reply.started":"2024-07-24T16:30:38.949844Z","shell.execute_reply":"2024-07-24T16:30:41.171628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import SegformerForSemanticSegmentation\nimport requests\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = SegformerForSemanticSegmentation.from_pretrained(\n    model_checkpoint,\n    num_labels=12,\n    id2label=id2label,\n    label2id=label2id,\n    ignore_mismatched_sizes=True,  # Will ensure the segmentation specific components are reinitialized.\n)\n\n\n\nmodel.load_state_dict(torch.load('/kaggle/input/segformer-weights/pytorch/default/3/SegFormerSegFormer-full3.pth'))\n\n#model.config","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:41.174035Z","iopub.execute_input":"2024-07-24T16:30:41.174329Z","iopub.status.idle":"2024-07-24T16:30:42.128751Z","shell.execute_reply.started":"2024-07-24T16:30:41.174304Z","shell.execute_reply":"2024-07-24T16:30:42.127808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.state_dict()['decode_head.linear_c.0.proj.weight'])\n#print(model1.state_dict()['decode_head.linear_c.0.proj.weight'])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:42.129987Z","iopub.execute_input":"2024-07-24T16:30:42.130328Z","iopub.status.idle":"2024-07-24T16:30:42.165902Z","shell.execute_reply.started":"2024-07-24T16:30:42.130300Z","shell.execute_reply":"2024-07-24T16:30:42.164839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(model[\"segformer.encoder.patch_embeddings.0.proj\"].weight)\n# Freeze all the layers first\nfor i, (name, param) in enumerate(model.named_parameters()):\n    if not \"decode_head\" in name:\n        param.requires_grad = False\n        \n    #decoder_layers_to_freeze = [\"0\",\"1\",\"2\"]\n    #if any(el in name for el in decoder_layers_to_freeze):\n    #    param.requires_grad = False\n\n\nfor name, param in model.named_parameters():\n    break\n    print(f\"{name}: {param.requires_grad}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:42.167417Z","iopub.execute_input":"2024-07-24T16:30:42.167786Z","iopub.status.idle":"2024-07-24T16:30:42.174463Z","shell.execute_reply.started":"2024-07-24T16:30:42.167753Z","shell.execute_reply":"2024-07-24T16:30:42.173491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_scheduler\nfrom tqdm.auto import tqdm\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=config.lr) #config.lr\nmodel.to(device)\nnum_epochs = config.epochs\nnum_training_steps = num_epochs * len(train_loader)\nnum_val_steps = num_epochs * len(valid_loader)\n\n\nlr_scheduler = get_scheduler(\n    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:42.175599Z","iopub.execute_input":"2024-07-24T16:30:42.175879Z","iopub.status.idle":"2024-07-24T16:30:42.203267Z","shell.execute_reply.started":"2024-07-24T16:30:42.175855Z","shell.execute_reply":"2024-07-24T16:30:42.202529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"mean_iou\")\n\ndef compute_metrics(logits,labels,per_category=False):\n  with torch.no_grad():\n    #logits, labels = eval_pred\n    #logits_tensor = torch.from_numpy(logits)\n    # scale the logits to the size of the label\n    logits_tensor = nn.functional.interpolate(\n        logits,\n        size=labels.shape[-2:],\n        mode=\"bilinear\",\n        align_corners=False,\n    ).argmax(dim=1)\n\n    pred_labels = logits_tensor.detach().cpu().numpy()\n    labels = labels.detach().cpu().numpy()\n    \n    # currently using _compute instead of compute\n    # see this issue for more info: https://github.com/huggingface/evaluate/pull/328#issuecomment-1286866576\n    metrics = metric._compute(\n            predictions=pred_labels,\n            references=labels,\n            num_labels=12,\n            ignore_index=255,\n            reduce_labels=False,\n        )\n    if per_category:\n        # add per category metrics as individual key-value pairs\n        per_category_miou = metrics.pop(\"per_category_miou\").tolist()\n        per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n\n        metrics.update({f\"miou_{id2label[i]}\": v for i, v in enumerate(per_category_miou)})\n        metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n    \n    return metrics\n\nprogress_bar_train = tqdm(range(num_training_steps))\nprogress_bar_val = tqdm(range(num_val_steps))\n#wandb.watch(model, log_freq=100)\n\n\nmodel.train()\ncnt = 0\nfor epoch in range(num_epochs):\n    training_loss_epoch = 0\n    training_miou_epoch = 0\n    \n    for batch_idx, (train_features_batch, train_labels_batch) in enumerate(train_loader):\n        optimizer.zero_grad()\n\n        outputs = model(train_features_batch,train_labels_batch)\n        \n        loss = outputs.loss # NllLoss2DBackward0\n            \n        metrics = compute_metrics(outputs['logits'], train_labels_batch)\n        training_loss_epoch += loss.item()\n        training_miou_epoch += metrics['mean_iou']\n            \n        loss.backward()\n        optimizer.step() \n        lr_scheduler.step()\n        progress_bar_train.update(1)\n        \n        \n    validation_loss_epoch = 0\n    validation_miou_epoch = 0\n    \n    \n    for val_features_batch, val_labels_batch in valid_loader:\n\n        with torch.no_grad():       \n        \n            outputs = model(val_features_batch, val_labels_batch)\n\n            loss = outputs.loss # NllLoss2DBackward0\n            \n            metrics = compute_metrics(outputs['logits'], val_labels_batch)\n            \n            validation_loss_epoch += loss.item()\n            validation_miou_epoch += metrics['mean_iou']\n            \n            progress_bar_val.update(1)\n            \n    print(\"Saving model weights\")\n    torch.save(model.state_dict(), 'SegFormer'+ str(run_name) + str(epoch) + '.pth') \n        \n    print({'training_loss_epoch': training_loss_epoch/len(train_loader), 'validation_loss_epoch': validation_loss_epoch/len(valid_loader)})\n    print({'training_miou_epoch': training_miou_epoch/len(train_loader), 'validation_miou_epoch': validation_miou_epoch/len(valid_loader)})\n    wandb.log({'training_loss_epoch': training_loss_epoch/len(train_loader), 'validation_loss_epoch': validation_loss_epoch/len(valid_loader),\n               'training_miou_epoch': training_miou_epoch/len(train_loader), 'validation_miou_epoch': validation_miou_epoch/len(valid_loader)})","metadata":{"execution":{"iopub.status.busy":"2024-07-24T16:30:42.204265Z","iopub.execute_input":"2024-07-24T16:30:42.204521Z","iopub.status.idle":"2024-07-24T18:12:22.516992Z","shell.execute_reply.started":"2024-07-24T16:30:42.204499Z","shell.execute_reply":"2024-07-24T18:12:22.516009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n#nekaj   \nmodel.cpu()\ndel model\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-07-24T18:12:22.518593Z","iopub.execute_input":"2024-07-24T18:12:22.519219Z","iopub.status.idle":"2024-07-24T18:12:22.996995Z","shell.execute_reply.started":"2024-07-24T18:12:22.519175Z","shell.execute_reply":"2024-07-24T18:12:22.995972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-07-24T18:12:22.998305Z","iopub.execute_input":"2024-07-24T18:12:22.998672Z","iopub.status.idle":"2024-07-24T18:12:29.041608Z","shell.execute_reply.started":"2024-07-24T18:12:22.998638Z","shell.execute_reply":"2024-07-24T18:12:29.040824Z"},"trusted":true},"execution_count":null,"outputs":[]}]}