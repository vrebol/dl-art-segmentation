{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8986504,"sourceType":"datasetVersion","datasetId":5167996},{"sourceId":83642,"sourceType":"modelInstanceVersion","modelInstanceId":70236,"modelId":95328},{"sourceId":83919,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":70236,"modelId":95328}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-28T11:37:38.715769Z","iopub.execute_input":"2024-07-28T11:37:38.716157Z","iopub.status.idle":"2024-07-28T11:37:39.764701Z","shell.execute_reply.started":"2024-07-28T11:37:38.716117Z","shell.execute_reply":"2024-07-28T11:37:39.763830Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:37:39.767139Z","iopub.execute_input":"2024-07-28T11:37:39.767938Z","iopub.status.idle":"2024-07-28T11:37:54.530702Z","shell.execute_reply.started":"2024-07-28T11:37:39.767903Z","shell.execute_reply":"2024-07-28T11:37:54.529623Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.19.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import zipfile\nimport glob\nimport shutil\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nimport random\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport torch\nfrom torchvision import datasets,models\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.transforms import v2\nfrom torchvision.transforms import ColorJitter\nfrom transformers import MaskFormerImageProcessor\nimport evaluate\nfrom torch import nn\nimport torch.nn.functional as F\nimport wandb\nimport scipy\n\n\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:37:54.532363Z","iopub.execute_input":"2024-07-28T11:37:54.533251Z","iopub.status.idle":"2024-07-28T11:38:13.782703Z","shell.execute_reply.started":"2024-07-28T11:37:54.533208Z","shell.execute_reply":"2024-07-28T11:38:13.781656Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-07-28 11:38:02.180837: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-28 11:38:02.180970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-28 11:38:02.319957: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"run_name = 'MaskFormer-cont2'\nwandb.init(project='aimlproject', name=run_name,save_code=True, config={\n            \"epochs\": 2,\n           \"batch_size\": 12,\n              \"lr\": 5e-5,\n          \"checkpoint\": \"facebook/maskformer-swin-tiny-ade\",\n           \"model_name\":\"SegFormer\", \"early_stopping\":False})  # mode='disabled',\nconfig = wandb.config","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:38:13.785360Z","iopub.execute_input":"2024-07-28T11:38:13.786265Z","iopub.status.idle":"2024-07-28T11:42:25.566139Z","shell.execute_reply.started":"2024-07-28T11:38:13.786228Z","shell.execute_reply":"2024-07-28T11:42:25.565246Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112735800000134, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"029db4c12df14695b332d1d3a47c876f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240728_114206-io38135u</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vrebol11/aimlproject/runs/io38135u' target=\"_blank\">MaskFormer-cont2</a></strong> to <a href='https://wandb.ai/vrebol11/aimlproject' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vrebol11/aimlproject' target=\"_blank\">https://wandb.ai/vrebol11/aimlproject</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vrebol11/aimlproject/runs/io38135u' target=\"_blank\">https://wandb.ai/vrebol11/aimlproject/runs/io38135u</a>"},"metadata":{}}]},{"cell_type":"code","source":"id2label = {\n            0: 'background',\n            1: 'bird',\n            2: 'boat',\n            3: 'bottle',\n            4: 'cat',\n            5: 'chair',\n            6: 'cow',\n            7: 'dog',\n            8: 'horse',\n            9: 'person',\n            10: 'pottedplant',\n            11: 'sheep',\n}\n\nlabel2id = {v: k for k, v in id2label.items()}\nmodel_checkpoint =  config.checkpoint\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:25.567529Z","iopub.execute_input":"2024-07-28T11:42:25.567901Z","iopub.status.idle":"2024-07-28T11:42:26.077837Z","shell.execute_reply.started":"2024-07-28T11:42:25.567866Z","shell.execute_reply":"2024-07-28T11:42:26.076798Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"EXPR_PATH = '/kaggle/input/art-seg-ready/pascal_sbd_styled_expressionism2/kaggle/working/pascal_sbd_styled_expressionism'\nIMPR_PATH = '/kaggle/input/art-seg-ready/pascal_sbd_styled_impressionism2/kaggle/working/pascal_sbd_styled_impressionism'\nPIMP_PATH = '/kaggle/input/art-seg-ready/pascal_sbd_styled_post_impressionism2/kaggle/working/pascal_sbd_styled_post_impressionism'\nREAL_PATH = '/kaggle/input/art-seg-ready/pascal_sbd_styled_realism2/kaggle/working/pascal_sbd_styled_realism'\nPATHS = [ EXPR_PATH, IMPR_PATH, PIMP_PATH, REAL_PATH ]\nPATHS_IM = [ os.path.join(path, 'images') for path in PATHS ]\nPATHS_LAB = [ os.path.join(path, 'labels') for path in PATHS ]","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:26.079147Z","iopub.execute_input":"2024-07-28T11:42:26.079444Z","iopub.status.idle":"2024-07-28T11:42:26.658619Z","shell.execute_reply.started":"2024-07-28T11:42:26.079418Z","shell.execute_reply":"2024-07-28T11:42:26.657563Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"PATHS","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:26.662191Z","iopub.execute_input":"2024-07-28T11:42:26.662537Z","iopub.status.idle":"2024-07-28T11:42:27.135123Z","shell.execute_reply.started":"2024-07-28T11:42:26.662508Z","shell.execute_reply":"2024-07-28T11:42:27.134056Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/art-seg-ready/pascal_sbd_styled_expressionism2/kaggle/working/pascal_sbd_styled_expressionism',\n '/kaggle/input/art-seg-ready/pascal_sbd_styled_impressionism2/kaggle/working/pascal_sbd_styled_impressionism',\n '/kaggle/input/art-seg-ready/pascal_sbd_styled_post_impressionism2/kaggle/working/pascal_sbd_styled_post_impressionism',\n '/kaggle/input/art-seg-ready/pascal_sbd_styled_realism2/kaggle/working/pascal_sbd_styled_realism']"},"metadata":{}}]},{"cell_type":"code","source":"#print(os.listdir('/kaggle/input/art-seg-ready/pascal_sbd_styled_realism1/pascal_sbd_styled_realism1/kaggle/working/pascal_sbd_styled_realism/images'))\ndef plot_random_images(allstyles=True,path=''):\n    selected_images = []\n    if allstyles:\n    #image_files = [f for f in os.listdir(basepath + '/dataset'+config.dataset+trainfolder) if f.startswith(startchar)]\n        shuffled_paths = PATHS_IM\n        random.shuffle(shuffled_paths)\n        \n        for i in range(len(PATHS)-1):\n            path = shuffled_paths[i]\n            image_files = os.listdir(path)\n            image_files = random.sample(image_files, 2) \n            image_files = [ os.path.join(path, image) for image in image_files]\n            selected_images += image_files\n            \n            \n        path = shuffled_paths[3]\n\n        image_files = os.listdir(path)\n        image_files = random.sample(image_files,3)\n        image_files = [ os.path.join(path, image) for image in image_files]\n        selected_images += image_files\n             \n    else:\n        if path == '':\n            print('empty path, useless')\n            return \n        image_files = os.listdir(path)\n        image_files = random.sample(image_files, 9)\n        image_files = [ os.path.join(path, image) for image in image_files]\n        selected_images += image_files\n\n    #selected_images = random.sample(image_files, 9)\n\n    rows = 3\n    cols = 3\n    fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n\n    # Plot each selected image\n    for i, image_name in enumerate(selected_images):\n        #img_path = os.path.join(basepath + '/dataset'+config.dataset+trainfolder, image_name)\n        img = mpimg.imread(image_name)\n        ax = axes[i // cols, i % cols]\n        ax.imshow(img)\n        ax.axis('off')\n\n    # Adjust layout\n    plt.tight_layout()\n    plt.show()\n\nplot_random_images()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:27.138965Z","iopub.execute_input":"2024-07-28T11:42:27.139378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_list = []\nfor i in range(4):\n    style_list = os.listdir(PATHS_LAB[i])\n    style_list = [ os.path.join(PATHS_LAB[i], image) for image in style_list]\n    train_list += style_list\n    \n    \n#train_list,test_list = train_test_split(train_list, test_size=0.2, random_state=0)\ntrain_list,val_list = train_test_split(train_list, test_size=0.2, random_state=0)\n\n#print(train_list[1], train_list[-1])\nexample_conv = train_list[2020]\nexample_conv = example_conv[:-4] + '.jpg'\n#example_conv = os.path.join()\nexample_conv = example_conv.replace(\"/labels/\", \"/images/\")\nprint(example_conv)","metadata":{"execution":{"iopub.status.idle":"2024-07-28T11:42:31.034846Z","shell.execute_reply.started":"2024-07-28T11:42:29.715668Z","shell.execute_reply":"2024-07-28T11:42:31.033941Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/input/art-seg-ready/pascal_sbd_styled_expressionism2/kaggle/working/pascal_sbd_styled_expressionism/images/2009_002240-stylized-expressionism_chaim-soutine_1937_9223372032559811545.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"\nclass PaintingSegDataset(Dataset):\n    def __init__(self, file_list, transform=None,train=True,use_gpu=torch.cuda.is_available()): #df(1st)\n        self.file_list = file_list\n        self.transform = transform\n        self.filelength = len(file_list)\n        self.jitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1) \n        self.train = train\n        self.use_gpu = use_gpu\n        self.id_to_trainid = {\n            0: 0,\n            3: 1,\n            4: 2,\n            5: 3,\n            8: 4,\n            9: 5,\n            10: 6,\n            12: 7,\n            13: 8,\n            15: 9,\n            16: 10,\n            17: 11,\n        }\n        #if(train):\n        #    self.folderpath = basepath +'/dataset' + config.dataset +trainfolder\n        #else:\n        #    self.folderpath = basepath +'/dataset'+config.dataset+testfolder\n\n\n    def __len__(self):\n        return self.filelength\n\n    def __getitem__(self, idx):\n        label_path = self.file_list[idx]\n        \n        img_path = label_path[:-4] + '.jpg'\n        img_path = img_path.replace(\"/labels/\", \"/images/\")\n        \n        img_orig = Image.open(img_path).convert('RGB')\n        \n        if label_path[-3:] == 'png':\n            label = np.array(Image.open(label_path), dtype=np.float32)\n        else:  # .mat\n            label = scipy.io.loadmat(label_path)[\"GTcls\"][0]['Segmentation'][0]\n            \n        \n        \n        label_copy = 255 * np.ones(label.shape, dtype=np.int8)\n        for k, v in self.id_to_trainid.items():\n            label_copy[label == k] = v\n        \n        label = Image.fromarray(label_copy)\n        #label = label.convert('L')\n        #print(label)\n        img = self.jitter(img_orig)     \n        \n        #transform = v2.Compose([v2.Resize((512,512))])\n        #img_orig = transform(img_orig)\n        label_transform = v2.Compose([v2.Resize((512,512)),v2.PILToTensor()])\n        label_tensor = label_transform(label).squeeze()\n            \n        return img, label,label_tensor #,img_orig","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:31.038922Z","iopub.execute_input":"2024-07-28T11:42:31.039234Z","iopub.status.idle":"2024-07-28T11:42:31.592719Z","shell.execute_reply.started":"2024-07-28T11:42:31.039207Z","shell.execute_reply":"2024-07-28T11:42:31.591717Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"image_processor = MaskFormerImageProcessor.from_pretrained(model_checkpoint)\n\n#test_dataset = PaintingSegDataset(test_list,transform=image_processor,train=False) #df\nval_dataset = PaintingSegDataset(val_list,transform=image_processor,train=True) #df\ntrain_dataset = PaintingSegDataset(train_list,transform=image_processor,train=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:31.594325Z","iopub.execute_input":"2024-07-28T11:42:31.594758Z","iopub.status.idle":"2024-07-28T11:42:32.296167Z","shell.execute_reply.started":"2024-07-28T11:42:31.594723Z","shell.execute_reply":"2024-07-28T11:42:32.295198Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4150f494c4324812826e9863a46cea60"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/maskformer/image_processing_maskformer.py:412: FutureWarning: The `size_divisibility` argument is deprecated and will be removed in v4.27. Please use `size_divisor` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/models/maskformer/image_processing_maskformer.py:419: FutureWarning: The `max_size` argument is deprecated and will be removed in v4.27. Please use size['longest_edge'] instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"a,b,c = train_dataset[4]\nprint(a)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:32.297975Z","iopub.execute_input":"2024-07-28T11:42:32.298369Z","iopub.status.idle":"2024-07-28T11:42:32.920505Z","shell.execute_reply.started":"2024-07-28T11:42:32.298333Z","shell.execute_reply":"2024-07-28T11:42:32.919381Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<PIL.Image.Image image mode=RGB size=504x376 at 0x7E421F701E70>\n","output_type":"stream"}]},{"cell_type":"code","source":"use_gpu = True\n\ndef collate_fn(batch):\n    inputs = list(zip(*batch))\n    img = inputs[0]\n    labels = inputs[1]\n    \n    batch = image_processor(images=img, segmentation_maps=labels, return_tensors=\"pt\",size=(512,512))\n    \n    return batch\n\n\ndef collate_fn_val(batch):\n    inputs = list(zip(*batch))\n    img = inputs[0]\n    labels = inputs[1]\n    \n    batch = image_processor(images=img, segmentation_maps=labels, return_tensors=\"pt\",size=(512,512))\n    batch['gt_labels'] = inputs[2]\n    \n    return batch\n\nbatch_size = config.batch_size \ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\nvalid_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_val)\n#test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n\nbatch = next(iter(valid_loader))\n#print(batch)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:32.923400Z","iopub.execute_input":"2024-07-28T11:42:32.923707Z","iopub.status.idle":"2024-07-28T11:42:34.158390Z","shell.execute_reply.started":"2024-07-28T11:42:32.923680Z","shell.execute_reply":"2024-07-28T11:42:34.157487Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"labels = [id2label[label] for label in batch[\"class_labels\"][0].tolist()]\n\n\n\ndef visualize_mask(labels, label_name, sample_index):\n    print(\"Label:\", label_name)\n    idx = labels.index(label_name)\n\n    visual_mask = (batch[\"mask_labels\"][sample_index][idx].bool().numpy() * 255).astype(np.uint8)\n    image = batch[\"orig_img\"][sample_index]\n    #img = np.array(image.convert('L'))\n    print(img.shape)\n    #img = np.transpose(img)\n    print(img.shape)\n    #label = Image.fromarray(visual_mask)\n    img = img * 0.5 + visual_mask * 0.5\n    img = img.astype(np.uint8)\n\n    plt.figure(figsize=(15, 10))\n    plt.imshow(img)\n    plt.show()\n    return \n\nprint(labels)\n#visualize_mask(labels, \"chair\",0)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:34.159686Z","iopub.execute_input":"2024-07-28T11:42:34.160072Z","iopub.status.idle":"2024-07-28T11:42:34.680147Z","shell.execute_reply.started":"2024-07-28T11:42:34.160038Z","shell.execute_reply":"2024-07-28T11:42:34.679103Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"['background', 'chair']\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import MaskFormerForInstanceSegmentation\nimport requests\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = MaskFormerForInstanceSegmentation.from_pretrained(\n    model_checkpoint,\n    num_labels=12,\n    id2label=id2label,\n    label2id=label2id,\n    ignore_mismatched_sizes=True,  # Will ensure the segmentation specific components are reinitialized.\n)\n#model\n\nmodel.load_state_dict(torch.load('/kaggle/input/maskformer-weights/pytorch/default/3/MaskFormer-cont10.pth'))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:34.681557Z","iopub.execute_input":"2024-07-28T11:42:34.683780Z","iopub.status.idle":"2024-07-28T11:42:41.084396Z","shell.execute_reply.started":"2024-07-28T11:42:34.683741Z","shell.execute_reply":"2024-07-28T11:42:41.083329Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/12.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88a025270da445b99f84a9c04649b3e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72fa8760619642348a344d720a437579"}},"metadata":{}},{"name":"stderr","text":"Some weights of MaskFormerForInstanceSegmentation were not initialized from the model checkpoint at facebook/maskformer-swin-tiny-ade and are newly initialized because the shapes did not match:\n- class_predictor.bias: found shape torch.Size([151]) in the checkpoint and torch.Size([13]) in the model instantiated\n- class_predictor.weight: found shape torch.Size([151, 256]) in the checkpoint and torch.Size([13, 256]) in the model instantiated\n- criterion.empty_weight: found shape torch.Size([151]) in the checkpoint and torch.Size([13]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"for i, (name, param) in enumerate(model.named_parameters()):\n    if \"encoder\" in name:\n        param.requires_grad = False\n        \n    #decoder_layers_to_freeze = [\"0\",\"1\",\"2\"]\n    #if any(el in name for el in decoder_layers_to_freeze):\n    #    param.requires_grad = False\n\n\nfor name, param in model.named_parameters():\n    break\n    #print(f\"{name}: {param.requires_grad}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:41.086505Z","iopub.execute_input":"2024-07-28T11:42:41.086851Z","iopub.status.idle":"2024-07-28T11:42:41.571853Z","shell.execute_reply.started":"2024-07-28T11:42:41.086774Z","shell.execute_reply":"2024-07-28T11:42:41.570121Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import get_scheduler\nfrom tqdm.auto import tqdm\n\noptimizer = torch.optim.Adam(model.parameters(), lr=config.lr) #config.lr\nmodel.to(device)\nnum_epochs = config.epochs\nnum_training_steps = num_epochs * len(train_loader)\nnum_val_steps = num_epochs * len(valid_loader)\n\n\nlr_scheduler = get_scheduler(\n    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:41.575119Z","iopub.execute_input":"2024-07-28T11:42:41.575556Z","iopub.status.idle":"2024-07-28T11:42:42.148608Z","shell.execute_reply.started":"2024-07-28T11:42:41.575516Z","shell.execute_reply":"2024-07-28T11:42:42.147540Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"mean_iou\")\n\n\nprogress_bar_train = tqdm(range(num_training_steps))\nprogress_bar_val = tqdm(range(num_val_steps))\n\n\nmodel.train()\nfor epoch in range(num_epochs):\n    training_loss_epoch = 0\n    training_miou_epoch = 0\n    \n    for idx, batch in enumerate(train_loader):\n        optimizer.zero_grad()\n\n        #outputs = model(train_features_batch,train_labels_batch)\n        outputs = model(\n          pixel_values=batch[\"pixel_values\"].to(device),\n          mask_labels=[labels.to(device) for labels in batch[\"mask_labels\"]],\n          class_labels=[labels.to(device) for labels in batch[\"class_labels\"]],\n      )\n        loss = outputs.loss # NllLoss2DBackward0\n        \n        training_loss_epoch += loss.item()\n        #training_miou_epoch += metrics['mean_iou']\n            \n        loss.backward()\n        optimizer.step() \n        lr_scheduler.step()\n        progress_bar_train.update(1)\n        \n        \n    validation_loss_epoch = 0\n    validation_miou_epoch = 0\n    \n    for idx, batch in enumerate(valid_loader):\n\n        with torch.no_grad():   \n            pixel_values = batch[\"pixel_values\"]\n        \n            outputs = model(\n                pixel_values=pixel_values.to(device),\n                mask_labels=[labels.to(device) for labels in batch[\"mask_labels\"]],\n                class_labels=[labels.to(device) for labels in batch[\"class_labels\"]])\n\n            validation_loss_epoch += loss.item()\n            target_sizes = [(512,512) for image in pixel_values]\n            predicted_segmentation_maps = image_processor.post_process_semantic_segmentation(outputs,\n                                                                                  target_sizes=target_sizes)\n            \n            # get ground truth segmentation maps\n            ground_truth_segmentation_maps = batch[\"gt_labels\"]\n            training_loss_epoch += loss.item()\n            \n            #print(ground_truth_segmentation_maps[0].shape)  \n            #print(predicted_segmentation_maps[0].shape)\n\n            metrics = metric.compute(references=ground_truth_segmentation_maps, predictions=predicted_segmentation_maps, num_labels=12, ignore_index=255)\n            validation_miou_epoch += metrics['mean_iou']\n            progress_bar_val.update(1)\n            \n            \n    print(\"Saving model weights\")\n    torch.save(model.state_dict(), str(run_name) + str(epoch) + '.pth')\n    \n    print({'training_loss_epoch': training_loss_epoch/len(train_loader), 'validation_loss_epoch': validation_loss_epoch/len(valid_loader)})\n    print({'validation_miou_epoch': validation_miou_epoch/len(valid_loader)})\n    wandb.log({'training_loss_epoch': training_loss_epoch/len(train_loader), 'validation_loss_epoch': validation_loss_epoch/len(valid_loader),\n               'validation_miou_epoch': validation_miou_epoch/len(valid_loader)})","metadata":{"execution":{"iopub.status.busy":"2024-07-28T11:42:42.150253Z","iopub.execute_input":"2024-07-28T11:42:42.150661Z","iopub.status.idle":"2024-07-28T13:15:35.051842Z","shell.execute_reply.started":"2024-07-28T11:42:42.150618Z","shell.execute_reply":"2024-07-28T13:15:35.050921Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/12.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65e899ca90594391aa619ffd2bcf28c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4460 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a593793b2054219a66020d82dee9a11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1116 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b55487c56dc48259d35805f16e3cb4f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/features/image.py:348: UserWarning: Downcasting array dtype int64 to int32 to be compatible with 'Pillow'\n  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n","output_type":"stream"},{"name":"stdout","text":"Saving model weights\n{'training_loss_epoch': 1.1755792117172292, 'validation_loss_epoch': 0.8417295217514038}\n{'validation_miou_epoch': 0.24614224684767155}\n","output_type":"stream"},{"name":"stderr","text":"/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:259: RuntimeWarning: invalid value encountered in divide\n  iou = total_area_intersect / total_area_union\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n","output_type":"stream"},{"name":"stdout","text":"Saving model weights\n{'training_loss_epoch': 1.195798421066438, 'validation_loss_epoch': 0.953302800655365}\n{'validation_miou_epoch': 0.25223069744525256}\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\n# VGGHUHIOdddggghhhhtttfffgjhghgjgjhgjfewgfw\nmodel.cpu()\ndel model\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T13:15:35.053226Z","iopub.execute_input":"2024-07-28T13:15:35.053579Z","iopub.status.idle":"2024-07-28T13:15:36.309097Z","shell.execute_reply.started":"2024-07-28T13:15:35.053545Z","shell.execute_reply":"2024-07-28T13:15:36.308101Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T13:15:36.310373Z","iopub.execute_input":"2024-07-28T13:15:36.310667Z","iopub.status.idle":"2024-07-28T13:15:43.876797Z","shell.execute_reply.started":"2024-07-28T13:15:36.310638Z","shell.execute_reply":"2024-07-28T13:15:43.876075Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='2.311 MB of 2.311 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_loss_epoch</td><td>▁█</td></tr><tr><td>validation_loss_epoch</td><td>▁█</td></tr><tr><td>validation_miou_epoch</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_loss_epoch</td><td>1.1958</td></tr><tr><td>validation_loss_epoch</td><td>0.9533</td></tr><tr><td>validation_miou_epoch</td><td>0.25223</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">MaskFormer-cont2</strong> at: <a href='https://wandb.ai/vrebol11/aimlproject/runs/io38135u' target=\"_blank\">https://wandb.ai/vrebol11/aimlproject/runs/io38135u</a><br/> View project at: <a href='https://wandb.ai/vrebol11/aimlproject' target=\"_blank\">https://wandb.ai/vrebol11/aimlproject</a><br/>Synced 5 W&B file(s), 0 media file(s), 16 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240728_114206-io38135u/logs</code>"},"metadata":{}}]}]}